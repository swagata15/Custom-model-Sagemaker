#!/usr/bin/env python3.5

# A sample training component that trains a simple scikit-learn decision tree model.
# This implementation works in File mode and makes no assumptions about the input file names.
# Input is specified as CSV with a data point in each row and the labels in the first column.

from __future__ import print_function

import os
import json
import pickle
import sys
import traceback
import joblib
import pandas as pd
import numpy as np


from cpt.cpt import Cpt

# These are the paths to where SageMaker mounts interesting things in your container.

prefix = '/opt/ml/'

input_path = prefix + 'input/data'
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')

# This algorithm has a single channel of input data called 'training'. Since we run in
# File mode, the input files are copied to the directory specified here.
channel_name='training'
training_path = os.path.join(input_path, channel_name)

# The function to execute the training.
def train():
    print('\nStarting the training.')
    try:
     # Take the set of files and read them all into a single pandas dataframe
        input_files = [ os.path.join(training_path, file) for file in os.listdir(training_path) ]
        if len(input_files) == 0:
            raise ValueError(('There are no files in {}.\n' +
                              'This usually indicates that the channel ({}) was incorrectly specified,\n' +
                              'the data specification in S3 was incorrectly specified or the role specified\n' +
                              'does not have permission to access the data.').format(training_path, channel_name))
        raw_data = [ pd.read_csv(file, header=None) for file in input_files ]
        train_data = pd.concat(raw_data)
          # Take the set of files and read them all into a single pandas dataframe
        #train_data = pd.read_csv(os.path.join(training_path, "shape-suggest.csv"))

        # labels are in the first column
        
        X = train_data.ix[:,0]
        Y = train_data.ix[:,1]
        #X = train_data['start'].values
        #Y = train_data['finish'].values
        shuffler = np.random.permutation(len(X))
        X_shuffled = X[shuffler]
        Y_shuffled = Y[shuffler]
        split_num = int(len(X) * 0.8)
        X_train = X_shuffled[:split_num]
        Y_train = Y_shuffled[:split_num]
        X_test = X_shuffled[split_num:]
        Y_test = Y_shuffled[split_num:]
        zips = list(zip(X_train, Y_train))	
        train_merged = [str(a[0]) + str(a[1]) for a in zips]
        # Now use cpt to train the model.
        #print(train_merged)
        clf = Cpt()
        clf = clf.fit(train_merged)

     
       # save the model
        with open(os.path.join(model_path, 'cpt.pkl'), 'wb') as out:
            pickle.dump(clf, out, protocol=0)
        print('Training complete.')
    except Exception as e:
        # Write out an error file. This will be returned as the failureReason in the
        # DescribeTrainingJob result.
        trc = traceback.format_exc()
        with open(os.path.join(output_path, 'failure'), 'w') as s:
            s.write('Exception during training: ' + str(e) + '\n' + trc)
        # Printing this causes the exception to be in the training job logs, as well.
        print('Exception during training: ' + str(e) + '\n' + trc, file=sys.stderr)
        # A non-zero exit code causes the training job to be marked as Failed.
        sys.exit(255)

if __name__ == '__main__':
    train()

    # A zero exit code causes the job to be marked a Succeeded.
    sys.exit(0)
